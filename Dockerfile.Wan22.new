FROM nvcr.io/nvidia/pytorch:24.04-py3

SHELL ["/bin/bash", "-c"]
WORKDIR /workspace

# Environment
ENV HF_HOME=/root/.cache/huggingface \
    TRANSFORMERS_CACHE=/root/.cache/huggingface \
    HF_HUB_ENABLE_HF_TRANSFER=1 \
    PIP_NO_CACHE_DIR=1 \
    PYTHONUNBUFFERED=1 \
    CUDA_VISIBLE_DEVICES=0

# System dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
      git ffmpeg \
    && rm -rf /var/lib/apt/lists/*

# Clone Wan 2.2
RUN git clone https://github.com/Wan-Video/Wan2.2.git /workspace/Wan2.2

# Install Python dependencies (exclude torch/flash_attn)
RUN pip install -U pip setuptools wheel && \
    cd /workspace/Wan2.2 && \
    grep -vE '^(torch|torchvision|torchaudio|flash_attn)\b' requirements.txt > /tmp/wan22_filtered.txt && \
    pip install -r /tmp/wan22_filtered.txt

# Pin stable versions for V100 compatibility
RUN pip install -U \
      "huggingface_hub<1.0" \
      "transformers==4.51.3" \
      "peft==0.17.1" \
      "diffusers==0.36.0" \
      hf_transfer \
      decord

# Optional requirements
RUN cd /workspace/Wan2.2 && \
    pip install -r requirements_animate.txt && \
    pip install -r requirements_s2v.txt

# Download model at build time
RUN python -c "from huggingface_hub import snapshot_download; \
    snapshot_download('Wan-AI/Wan2.2-TI2V-5B', local_dir='/workspace/Wan2.2/Wan2.2-TI2V-5B')"

# Single GPU smoke test
RUN cat > /workspace/test_gpu.py << 'EOF'
import torch
print(f"PyTorch: {torch.__version__}")
print(f"CUDA: {torch.cuda.is_available()}")
print(f"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}")
print(f"VRAM: {torch.cuda.get_device_properties(0).total_memory/1024**3:.1f}GB" if torch.cuda.is_available() else "")
EOF

CMD ["python", "/workspace/test_gpu.py"]
